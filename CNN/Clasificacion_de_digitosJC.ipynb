{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juancarlosch1708-spec/IA/blob/main/CNN/Clasificacion_de_digitosJC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6_yOfHt278O"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importa un conjunto de datos de dígitos escritos a mano (0–9) de scikit-learn y lo carga en la variable digits.\n",
        "Este dataset se usa para entrenar y probar modelos de reconocimiento de números."
      ],
      "metadata": {
        "id": "fcn4a2wk3rM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits.keys()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_DO8fEf3sEV",
        "outputId": "cbe4a6c4-1f79-4b1e-9fd1-b887852fa544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra los nombres de los elementos que contiene el dataset digits (como imágenes, etiquetas, descripción, etc.)."
      ],
      "metadata": {
        "id": "trmpi7TP3xlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_keys([\n",
        "    'data', 'target', 'frame',\n",
        "    'feature_names', 'target_names', 'images',\n",
        "    'DESCR'\n",
        "])\n"
      ],
      "metadata": {
        "id": "wj0U2egP4DdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos son los componentes del dataset digits:\n",
        "\n",
        "\n",
        "data → Los datos de cada imagen en forma de números.\n",
        "\n",
        "\n",
        "target → Las etiquetas (número real 0–9).\n",
        "\n",
        "\n",
        "frame → (A veces vacío) versión tipo DataFrame.\n",
        "\n",
        "\n",
        "feature_names → Nombres de características (no siempre usado).\n",
        "\n",
        "\n",
        "target_names → Nombres de las clases (0–9).\n",
        "\n",
        "\n",
        "images → Las imágenes en forma de matriz 8×8.\n",
        "\n",
        "\n",
        "DESCR → Descripción del dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "dcsjf2Nn3_jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.DESCR)\n"
      ],
      "metadata": {
        "id": "oCcLhL-F4EhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra la descripción completa del dataset digits:\n",
        "incluye su origen, para qué sirve, cuántas muestras tiene y cómo están representadas las imágenes."
      ],
      "metadata": {
        "id": "hLI8S3tj4HEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n"
      ],
      "metadata": {
        "id": "y8c2Xy5g4MM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guarda el número 0 en la variable index.\n",
        "Esto normalmente se usa para seleccionar la primera imagen del dataset."
      ],
      "metadata": {
        "id": "185LxQ0k4QDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = digits.images[index]\n",
        "label = digits.target[index]"
      ],
      "metadata": {
        "id": "3ka1oUqK4TST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "digits.images contiene las imágenes del dataset digits (cada una es una matriz 8x8).\n",
        "\n",
        "digits.target contiene las etiquetas correctas (el número que representa la imagen).\n",
        "\n",
        "index indica cuál imagen escoger (como lo definiste, index = 0, toma la primera).\n",
        "\n",
        "Entonces:\n",
        "\n",
        "image ahora guarda la primera imagen (un dígito escrito a mano).\n",
        "\n",
        "label guarda el número real representado en esa imagen."
      ],
      "metadata": {
        "id": "1QzBEyPR4SZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(image)\n"
      ],
      "metadata": {
        "id": "AbPnF-iC4ZFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "imprime la imagen"
      ],
      "metadata": {
        "id": "TJ1Y4K3l4bsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(image, cmap=plt.cm.gray)\n",
        "plt.title(f'Dígito: {label}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gGT5Uvz-4dMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "esto mostrará el número que representa esa imagen."
      ],
      "metadata": {
        "id": "0nOerVrh4sMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    digits.data, digits.target,\n",
        "    test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# One-hot encode the target variable\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n"
      ],
      "metadata": {
        "id": "2nJzNCT24unK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importa TensorFlow y herramientas para dividir datos."
      ],
      "metadata": {
        "id": "bzbIsCRa4uOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "id": "ya3eZYwu42LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "muestra el tamaño de los datos:\n",
        "\n",
        "X_train.shape → cuántas imágenes se usan para entrenar.\n",
        "\n",
        "X_test.shape → cuántas imágenes se usan para probar.\n",
        "\n",
        "Cada imagen tiene 64 valores (porque es de 8x8 pixeles)."
      ],
      "metadata": {
        "id": "bJhTZdcY4-2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_tensor = tf.reshape(X_train[0], shape=(8, 8))\n",
        "print(reshaped_tensor)\n"
      ],
      "metadata": {
        "id": "li-fSCb44_4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "está reorganizando el vector de 64 valores de la imagen (8×8 pixeles) nuevamente a su forma original de matriz 8x8, para poder verla como una imagen en lugar de una lista. Luego se imprime esa matriz."
      ],
      "metadata": {
        "id": "d8khtePz5GzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "DXfFMr7J5wVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "StandardScaler() ajusta los valores para que tengan media 0 y desviación estándar 1.\n",
        "Esto ayuda a que la red neuronal aprenda mejor y más rápido.\n",
        "\n",
        "fit_transform calcula la escala y transforma el conjunto de entrenamiento.\n",
        "\n",
        "transform aplica la misma escala al conjunto de prueba."
      ],
      "metadata": {
        "id": "GxgSAcik50yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_tensor = tf.reshape(X_train[0], shape=(8, 8))\n",
        "# Redondeamos para tener una mejor visualizacion\n",
        "reshaped_tensor =  tf.floor(reshaped_tensor * 100) / 100\n",
        "print(reshaped_tensor)"
      ],
      "metadata": {
        "id": "m-5MestZ54Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.reshape(X_train[0], (8, 8)) vuelve a darle forma al primer dato para mostrarlo como imagen de 8x8.\n",
        "\n",
        "\n",
        "tf.floor(reshaped_tensor * 100) / 100 redondea los valores a solo 2 decimales para que se vea más claro al imprimir.\n",
        "\n",
        "\n",
        "print(reshaped_tensor) lo muestra en pantalla.\n",
        "\n"
      ],
      "metadata": {
        "id": "o_E6Mo2m6GD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redimensionar el tensor a la forma (total, 8, 8)\n",
        "X_train = tf.reshape(X_train, (X_train.shape[0], 8, 8))\n",
        "X_test = tf.reshape(X_test, (X_test.shape[0], 8, 8))"
      ],
      "metadata": {
        "id": "Semla17J6G_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estamos reconstruyendo las imágenes para que tengan forma de imagen (8x8) en lugar de estar aplastadas en un vector."
      ],
      "metadata": {
        "id": "Asodv8Lg6T2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# Crear el modelo de CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3),\n",
        "        activation='relu',\n",
        "        input_shape=(8, 8, 1)\n",
        "    ),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "gAOAhN8j6Vwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ste modelo usa una red neuronal convolucional (CNN) para reconocer dígitos convirtiendo la imagen en características y luego clasificándola en una de las 10 clases."
      ],
      "metadata": {
        "id": "rzT7WnKs6cpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tasa de aprendizaje deseada\n",
        "learning_rate = 0.001\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "h5ZJPZvO6de7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "estamos creando el optimizador Adam con una velocidad de aprendizaje de 0.001 para entrenar el modelo de forma estable."
      ],
      "metadata": {
        "id": "KaBFCd6J6jDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "6ts0BAIb6kIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí configuramos cómo el modelo va a aprender, cómo va a calcular su error y qué medida de desempeño queremos ver."
      ],
      "metadata": {
        "id": "rnQF5y4w6rQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "Fvo1X4o-6plY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "entrena el modelo usando el 80% de los datos y usa el 20% restante para evaluar cómo va aprendiendo."
      ],
      "metadata": {
        "id": "lZCYIIAw63Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.title('Función de pérdida durante el entrenamiento')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oL425CCR64dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Te permite ver si el modelo mejora o si se está sobreajustando (overfitting)."
      ],
      "metadata": {
        "id": "wojdQZTD6-XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "cFy1Byog6_If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "te dice qué tan bien funciona tu modelo con datos nuevos."
      ],
      "metadata": {
        "id": "RSGkKvd57EJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "# Convert y_test back to multiclass format\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "sensitivity = recall_score(y_test_classes, y_pred_classes, average=None)"
      ],
      "metadata": {
        "id": "-hbrCSz77E3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código convierte las predicciones a clases, genera la matriz de confusión y calcula qué tan bien el modelo reconoce cada número."
      ],
      "metadata": {
        "id": "8XkKLL6V7Ko5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizar la matriz de confusión como una imagen de colores\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Mostrar la sensibilidad (recall) para cada clase\n",
        "print('Sensitivity (Recall) for each class:')\n",
        "for i in range(10):\n",
        "    print(f'Class {i}: {sensitivity[i]}')"
      ],
      "metadata": {
        "id": "z2i7w-j_7NBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí se visualiza la matriz de confusión como una imagen y se imprime qué tan bien el modelo identifica cada número."
      ],
      "metadata": {
        "id": "CkFdyLVo7SID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cambia por el nombre de tu archivo\n",
        "ruta = \"/content/mi_numero.png\"\n",
        "# Escala de grises (\"L\")\n",
        "img = Image.open(ruta).convert(\"L\")\n",
        "\n",
        "# mostrar la imagen\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.title(\"Imagen original\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gV0By8C37S5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código carga tu imagen, la pasa a blanco y negro y la muestra."
      ],
      "metadata": {
        "id": "ILptko127gcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# redimensionar a 8x8\n",
        "img_resized = img.resize((8, 8), Image.Resampling.LANCZOS)\n",
        "\n",
        "# mostrar imagen\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(img_resized, cmap=\"gray\")\n",
        "plt.title(\"Imagen redimensionada a 8x8\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# opcional, guardamos la imagen si es necesario\n",
        "img_resized.save(\"imagen_8x8.png\")\n"
      ],
      "metadata": {
        "id": "ceqbalMW7hAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código toma la imagen original, la reduce a 8x8 para que el modelo pueda clasificarla, la muestra y opcionalmente la guarda."
      ],
      "metadata": {
        "id": "0lrJM5H97mOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# reescalar de 0-255 a 0-16 e invertir (fondo negro = 0)\n",
        "img_array = np.array(img_resized).astype(\"float32\")\n",
        "img_array = 16 - (img_array / 255 * 16)\n",
        "\n",
        "# mostrar imagen\n",
        "plt.imshow(img_array, cmap=\"gray\")\n",
        "plt.title(\"Imagen reescalada e invertida (0-16)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g_F9Iyb47oIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código convierte la imagen redimensionada al mismo formato numérico que usa el dataset digits (escala 0-16 y colores invertidos) y la muestra."
      ],
      "metadata": {
        "id": "12dXTPwj7tFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# normalizar\n",
        "scaler = StandardScaler()\n",
        "img_flat = img_array\n",
        "img_scaled = scaler.fit_transform(img_flat)\n",
        "\n",
        "# Dar forma (1,8,8) que es el input del modelo\n",
        "img_tensor = img_scaled.reshape(1, 8, 8)"
      ],
      "metadata": {
        "id": "oZHUNrex7vNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código normaliza la imagen y la acomoda con la forma que requiere la red neuronal para poder clasificarla."
      ],
      "metadata": {
        "id": "2Nfvdi427ywK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(img_tensor)\n",
        "digit = np.argmax(pred)\n",
        "print(\"Predicción:\", digit)"
      ],
      "metadata": {
        "id": "2WGMnHjU71OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo analiza la imagen y muestra qué número cree que es."
      ],
      "metadata": {
        "id": "UdePM9Sw755d"
      }
    }
  ]
}